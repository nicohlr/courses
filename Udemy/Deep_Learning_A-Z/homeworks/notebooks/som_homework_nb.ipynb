{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning A-Z : Building a SOM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "This notebook is my response to the fourth homework of the course called *Deep Learning A-Zâ„¢: Hands-On Artificial Neural Networks* accessible here : https://www.udemy.com/deeplearning/\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "In this notebook, we are going to build a Self Organizing Map (SOM) using minisom by following instructions given on the course. This will allow us to detect potential credit card fraud among customers who bought a credit card. We will use unsupervised learning to detect patterns (segments of customers) in data and one of those parttern will be the potential fraud.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from minisom import MiniSom\n",
    "from pylab import bone, pcolor, colorbar, plot, show\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraud detection will consist of identifiying outliers with a SOM. We will compute the mean of eclidian distance betweet a point and its neighborhood on the SOM. The points which will have the biggest MED will be the outliers (the potential fraudsters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15776156</td>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15739548</td>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15662854</td>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15687688</td>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15715750</td>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  A1     A2     A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  \\\n",
       "0    15776156   1  22.08  11.46   2   4   4  1.585   0   0    0    1    2   \n",
       "1    15739548   0  22.67   7.00   2   8   4  0.165   0   0    0    0    2   \n",
       "2    15662854   0  29.58   1.75   1   4   4  1.250   0   0    0    1    2   \n",
       "3    15687688   0  21.67  11.50   1   5   3  0.000   1   1   11    1    2   \n",
       "4    15715750   1  20.17   8.17   2   6   4  1.960   1   1   14    0    2   \n",
       "\n",
       "   A13   A14  Class  \n",
       "0  100  1213      0  \n",
       "1  160     1      0  \n",
       "2  280     1      0  \n",
       "3    0     1      1  \n",
       "4   60   159      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_train = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath('__file__')))), 'ressources/Self_Organizing_Maps/Credit_Card_Applications.csv')\n",
    "dataset = pd.read_csv(path_train)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last column contain informaton about if clients application was approuved of not. In this way, we will be able to compare, on the SOM, the customers who have approuval and those who do not have it (so we will be able to identify the customers who are fraudulent and who got their application approved)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes\n",
    "X = dataset.iloc[:, :-1].values\n",
    "# Class (approved of not)\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.42681467e-01, 1.00000000e+00, 1.25263158e-01, ...,\n",
       "        5.00000000e-01, 5.00000000e-02, 1.21200000e-02],\n",
       "       [6.96090562e-01, 0.00000000e+00, 1.34135338e-01, ...,\n",
       "        5.00000000e-01, 8.00000000e-02, 0.00000000e+00],\n",
       "       [3.88981656e-01, 0.00000000e+00, 2.38045113e-01, ...,\n",
       "        5.00000000e-01, 1.40000000e-01, 0.00000000e+00],\n",
       "       ...,\n",
       "       [4.39420332e-01, 0.00000000e+00, 7.63909774e-02, ...,\n",
       "        5.00000000e-01, 5.00000000e-02, 0.00000000e+00],\n",
       "       [8.44034934e-01, 0.00000000e+00, 2.05563910e-01, ...,\n",
       "        5.00000000e-01, 6.00000000e-02, 1.10000000e-04],\n",
       "       [1.06907888e-01, 1.00000000e+00, 4.09774436e-01, ...,\n",
       "        0.00000000e+00, 2.80000000e-01, 0.00000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features scaling (normalization)\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "X = sc.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building the SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing som\n",
    "som = MiniSom(x=10, y=10, input_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *x, y* is the size of the grid for the SOM\n",
    "- *input_len* is the number of features in our dataset\n",
    "- *learning rate* higher lr means quicker convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "som.random_weights_init(X) # initializing weights randomly close to 0\n",
    "som.train_random(data=X, num_iteration=100) # We don't train on X and y, just on X because it's unsueprvised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot the SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "pcolor(som.distance_map().T) # distance_map method will return all the mean distances for winning nodes in one matrix\n",
    "colorbar()\n",
    "\n",
    "# add red circles and green squares for customer who did not get approval and customer who got approval respectively\n",
    "markers = ['o', 's']\n",
    "colors = ['r', 'g']\n",
    "\n",
    "for i, x in enumerate(X):\n",
    "    w = som.winner(x) # get coordinate of winning node for observation x\n",
    "    plot(w[0] + 0.5, \n",
    "         w[1] + 0.5, # plot marker AT THE MIDDLE of the square representing the winning node\n",
    "         markers[y[i]],\n",
    "         markeredgecolor=colors[y[i]],\n",
    "         markerfacecolor='None',\n",
    "         markersize=10, # graphical settings\n",
    "         markeredgewidth=2) \n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that, on the white squared representing the outliers (so the potential frauds), there are customers which received an approval and customers which did not received the approval. Now, we have to catch the cheaters, in priority the ones who get approvals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Finding the frauds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = som.win_map(X) # dict containing the observations pet node of the SOM\n",
    "#frauds = mapping[2, 4] # get customers in white winning node of SOM above\n",
    "frauds = np.concatenate((mapping[6, 4], mapping[6, 7]), axis=0) # to concatenate 2 nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15687688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15668679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.42</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>1705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15738487.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.75</td>\n",
       "      <td>10.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15594305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.75</td>\n",
       "      <td>0.71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15664793.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.33</td>\n",
       "      <td>9.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID   A1     A2     A3   A4    A5   A6      A7   A8   A9   A10  A11  \\\n",
       "0  15687688.0  0.0  21.67  11.50  1.0   5.0  3.0   0.000  1.0  1.0  11.0  1.0   \n",
       "1  15668679.0  0.0  47.42   3.00  2.0  14.0  4.0  13.875  1.0  1.0   2.0  1.0   \n",
       "2  15738487.0  0.0  20.75  10.25  2.0  11.0  4.0   0.710  1.0  1.0   2.0  1.0   \n",
       "3  15594305.0  0.0  23.75   0.71  2.0   9.0  4.0   0.250  0.0  1.0   1.0  1.0   \n",
       "4  15664793.0  0.0  17.33   9.50  2.0   6.0  4.0   1.750  0.0  1.0  10.0  1.0   \n",
       "\n",
       "   A12    A13     A14  \n",
       "0  2.0    0.0     1.0  \n",
       "1  2.0  519.0  1705.0  \n",
       "2  2.0   49.0     1.0  \n",
       "3  2.0  240.0     5.0  \n",
       "4  2.0    0.0    11.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frauds = sc.inverse_transform(frauds)\n",
    "frauds = pd.DataFrame(frauds, columns=dataset.columns.tolist()[:-1])\n",
    "frauds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frauds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have the list of potential frauds !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Homework - Mega case study : combining ANN and SOM to get probability of frauds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I this part, we are going to combine supervised and unsupervides learning by building an ann which will take as input data output from SOM and will try to predict probability of frauds for each observation. Let's begin by creating a new dataframe with a new column 'fraud' which contains 1 for fraud predicted by the SOM and 0 for other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>Class</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15776156</td>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15739548</td>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15662854</td>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15687688</td>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15715750</td>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  A1     A2     A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  \\\n",
       "0    15776156   1  22.08  11.46   2   4   4  1.585   0   0    0    1    2   \n",
       "1    15739548   0  22.67   7.00   2   8   4  0.165   0   0    0    0    2   \n",
       "2    15662854   0  29.58   1.75   1   4   4  1.250   0   0    0    1    2   \n",
       "3    15687688   0  21.67  11.50   1   5   3  0.000   1   1   11    1    2   \n",
       "4    15715750   1  20.17   8.17   2   6   4  1.960   1   1   14    0    2   \n",
       "\n",
       "   A13   A14  Class  Fraud  \n",
       "0  100  1213      0      0  \n",
       "1  160     1      0      0  \n",
       "2  280     1      0      0  \n",
       "3    0     1      1      1  \n",
       "4   60   159      1      0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.copy()\n",
    "df['Fraud'] = d.apply(lambda row: 1 if row.CustomerID in frauds['CustomerID'].astype(int).tolist() else 0, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    643\n",
       "1     47\n",
       "Name: Fraud, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, let's use an ann to predict the probability of Fraud for each CustomerID using an ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.iloc[:, 1:16].values\n",
    "y2 = df.iloc[:, 16].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68873723, -0.80105183,  1.34711063, ..., -0.48835847,\n",
       "         0.03738039, -0.89530251],\n",
       "       [-1.45193254, -0.75124044,  0.45054795, ..., -0.13959116,\n",
       "        -0.19541334, -0.89530251],\n",
       "       [-1.45193254, -0.16785619, -0.60482292, ...,  0.55794344,\n",
       "        -0.19541334, -0.89530251],\n",
       "       ...,\n",
       "       [-1.45193254, -1.07543661,  0.96114643, ..., -0.48835847,\n",
       "        -0.19541334,  1.11694091],\n",
       "       [-1.45193254, -0.35021653,  1.95822062, ..., -0.3721027 ,\n",
       "        -0.19330052,  1.11694091],\n",
       "       [ 0.68873723,  0.79628971, -0.94857229, ...,  2.18552419,\n",
       "        -0.19541334,  1.11694091]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X2 = sc.fit_transform(X2)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(units=8, kernel_initializer='uniform', activation='relu', input_shape = (15,)))\n",
    "classifier.add(Dropout(p=0.1)) \n",
    "classifier.add(Dense(units=8, kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(p=0.1))\n",
    "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "690/690 [==============================] - 1s 1ms/step - loss: 0.6714 - acc: 0.9261\n",
      "Epoch 2/100\n",
      "690/690 [==============================] - 0s 219us/step - loss: 0.5410 - acc: 0.9319\n",
      "Epoch 3/100\n",
      "690/690 [==============================] - 0s 270us/step - loss: 0.3059 - acc: 0.9319\n",
      "Epoch 4/100\n",
      "690/690 [==============================] - 0s 286us/step - loss: 0.2068 - acc: 0.9319\n",
      "Epoch 5/100\n",
      "690/690 [==============================] - 0s 272us/step - loss: 0.1761 - acc: 0.9319\n",
      "Epoch 6/100\n",
      "690/690 [==============================] - 0s 261us/step - loss: 0.1668 - acc: 0.9319\n",
      "Epoch 7/100\n",
      "690/690 [==============================] - 0s 333us/step - loss: 0.1526 - acc: 0.9319\n",
      "Epoch 8/100\n",
      "690/690 [==============================] - 0s 271us/step - loss: 0.1434 - acc: 0.9319\n",
      "Epoch 9/100\n",
      "690/690 [==============================] - 0s 276us/step - loss: 0.1323 - acc: 0.9319\n",
      "Epoch 10/100\n",
      "690/690 [==============================] - 0s 303us/step - loss: 0.1220 - acc: 0.9319\n",
      "Epoch 11/100\n",
      "690/690 [==============================] - 0s 299us/step - loss: 0.1178 - acc: 0.9319\n",
      "Epoch 12/100\n",
      "690/690 [==============================] - 0s 274us/step - loss: 0.1079 - acc: 0.9319\n",
      "Epoch 13/100\n",
      "690/690 [==============================] - 0s 284us/step - loss: 0.1040 - acc: 0.9319\n",
      "Epoch 14/100\n",
      "690/690 [==============================] - 0s 285us/step - loss: 0.0980 - acc: 0.9319\n",
      "Epoch 15/100\n",
      "690/690 [==============================] - 0s 352us/step - loss: 0.0923 - acc: 0.9319\n",
      "Epoch 16/100\n",
      "690/690 [==============================] - 0s 344us/step - loss: 0.0878 - acc: 0.9319\n",
      "Epoch 17/100\n",
      "690/690 [==============================] - 0s 334us/step - loss: 0.0800 - acc: 0.9319\n",
      "Epoch 18/100\n",
      "690/690 [==============================] - 0s 286us/step - loss: 0.0785 - acc: 0.9319\n",
      "Epoch 19/100\n",
      "690/690 [==============================] - 0s 318us/step - loss: 0.0730 - acc: 0.9319\n",
      "Epoch 20/100\n",
      "690/690 [==============================] - 0s 317us/step - loss: 0.0730 - acc: 0.9319\n",
      "Epoch 21/100\n",
      "690/690 [==============================] - 0s 333us/step - loss: 0.0694 - acc: 0.9319\n",
      "Epoch 22/100\n",
      "690/690 [==============================] - 0s 286us/step - loss: 0.0712 - acc: 0.9319\n",
      "Epoch 23/100\n",
      "690/690 [==============================] - 0s 290us/step - loss: 0.0665 - acc: 0.9420\n",
      "Epoch 24/100\n",
      "690/690 [==============================] - 0s 265us/step - loss: 0.0624 - acc: 0.9768\n",
      "Epoch 25/100\n",
      "690/690 [==============================] - 0s 275us/step - loss: 0.0621 - acc: 0.9870\n",
      "Epoch 26/100\n",
      "690/690 [==============================] - 0s 273us/step - loss: 0.0594 - acc: 0.9826\n",
      "Epoch 27/100\n",
      "690/690 [==============================] - 0s 279us/step - loss: 0.0606 - acc: 0.9841\n",
      "Epoch 28/100\n",
      "690/690 [==============================] - 0s 247us/step - loss: 0.0592 - acc: 0.9899\n",
      "Epoch 29/100\n",
      "690/690 [==============================] - 0s 276us/step - loss: 0.0605 - acc: 0.9870\n",
      "Epoch 30/100\n",
      "690/690 [==============================] - 0s 273us/step - loss: 0.0592 - acc: 0.9884\n",
      "Epoch 31/100\n",
      "690/690 [==============================] - 0s 263us/step - loss: 0.0567 - acc: 0.9913\n",
      "Epoch 32/100\n",
      "690/690 [==============================] - 0s 266us/step - loss: 0.0564 - acc: 0.9884\n",
      "Epoch 33/100\n",
      "690/690 [==============================] - 0s 313us/step - loss: 0.0543 - acc: 0.9928\n",
      "Epoch 34/100\n",
      "690/690 [==============================] - 0s 303us/step - loss: 0.0533 - acc: 0.9899\n",
      "Epoch 35/100\n",
      "690/690 [==============================] - 0s 254us/step - loss: 0.0533 - acc: 0.9899\n",
      "Epoch 36/100\n",
      "690/690 [==============================] - 0s 240us/step - loss: 0.0526 - acc: 0.9913\n",
      "Epoch 37/100\n",
      "690/690 [==============================] - 0s 330us/step - loss: 0.0512 - acc: 0.9942\n",
      "Epoch 38/100\n",
      "690/690 [==============================] - 0s 385us/step - loss: 0.0504 - acc: 0.9928\n",
      "Epoch 39/100\n",
      "690/690 [==============================] - 0s 189us/step - loss: 0.0489 - acc: 0.9928\n",
      "Epoch 40/100\n",
      "690/690 [==============================] - 0s 273us/step - loss: 0.0483 - acc: 0.9942\n",
      "Epoch 41/100\n",
      "690/690 [==============================] - 0s 194us/step - loss: 0.0469 - acc: 0.9942\n",
      "Epoch 42/100\n",
      "690/690 [==============================] - 0s 383us/step - loss: 0.0466 - acc: 0.9928\n",
      "Epoch 43/100\n",
      "690/690 [==============================] - 0s 182us/step - loss: 0.0474 - acc: 0.9913\n",
      "Epoch 44/100\n",
      "690/690 [==============================] - 0s 261us/step - loss: 0.0454 - acc: 0.9957\n",
      "Epoch 45/100\n",
      "690/690 [==============================] - 0s 260us/step - loss: 0.0433 - acc: 0.9928\n",
      "Epoch 46/100\n",
      "690/690 [==============================] - 0s 299us/step - loss: 0.0429 - acc: 0.9957\n",
      "Epoch 47/100\n",
      "690/690 [==============================] - 0s 265us/step - loss: 0.0452 - acc: 0.9913\n",
      "Epoch 48/100\n",
      "690/690 [==============================] - 0s 240us/step - loss: 0.0425 - acc: 0.9913\n",
      "Epoch 49/100\n",
      "690/690 [==============================] - 0s 240us/step - loss: 0.0411 - acc: 0.9913\n",
      "Epoch 50/100\n",
      "690/690 [==============================] - 0s 282us/step - loss: 0.0410 - acc: 0.9884\n",
      "Epoch 51/100\n",
      "690/690 [==============================] - 0s 337us/step - loss: 0.0397 - acc: 0.9928\n",
      "Epoch 52/100\n",
      "690/690 [==============================] - 0s 251us/step - loss: 0.0379 - acc: 0.9986\n",
      "Epoch 53/100\n",
      "690/690 [==============================] - 0s 243us/step - loss: 0.0386 - acc: 0.9957\n",
      "Epoch 54/100\n",
      "690/690 [==============================] - 0s 279us/step - loss: 0.0362 - acc: 0.9971\n",
      "Epoch 55/100\n",
      "690/690 [==============================] - 0s 294us/step - loss: 0.0380 - acc: 0.9928\n",
      "Epoch 56/100\n",
      "690/690 [==============================] - 0s 221us/step - loss: 0.0351 - acc: 0.9957\n",
      "Epoch 57/100\n",
      "690/690 [==============================] - 0s 240us/step - loss: 0.0359 - acc: 0.9971\n",
      "Epoch 58/100\n",
      "690/690 [==============================] - 0s 242us/step - loss: 0.0332 - acc: 0.9971\n",
      "Epoch 59/100\n",
      "690/690 [==============================] - 0s 284us/step - loss: 0.0363 - acc: 0.9928\n",
      "Epoch 60/100\n",
      "690/690 [==============================] - 0s 391us/step - loss: 0.0366 - acc: 0.9928\n",
      "Epoch 61/100\n",
      "690/690 [==============================] - 0s 228us/step - loss: 0.0344 - acc: 0.9942\n",
      "Epoch 62/100\n",
      "690/690 [==============================] - 0s 218us/step - loss: 0.0338 - acc: 0.9957\n",
      "Epoch 63/100\n",
      "690/690 [==============================] - 0s 220us/step - loss: 0.0309 - acc: 0.9942\n",
      "Epoch 64/100\n",
      "690/690 [==============================] - 0s 219us/step - loss: 0.0316 - acc: 0.9957\n",
      "Epoch 65/100\n",
      "690/690 [==============================] - 0s 218us/step - loss: 0.0331 - acc: 0.9928\n",
      "Epoch 66/100\n",
      "690/690 [==============================] - 0s 283us/step - loss: 0.0298 - acc: 0.9971\n",
      "Epoch 67/100\n",
      "690/690 [==============================] - 0s 237us/step - loss: 0.0300 - acc: 0.9928\n",
      "Epoch 68/100\n",
      "690/690 [==============================] - 0s 205us/step - loss: 0.0290 - acc: 0.9942\n",
      "Epoch 69/100\n",
      "690/690 [==============================] - 0s 223us/step - loss: 0.0296 - acc: 0.9942\n",
      "Epoch 70/100\n",
      "690/690 [==============================] - 0s 253us/step - loss: 0.0285 - acc: 0.9957\n",
      "Epoch 71/100\n",
      "690/690 [==============================] - 0s 205us/step - loss: 0.0286 - acc: 0.9971\n",
      "Epoch 72/100\n",
      "690/690 [==============================] - 0s 232us/step - loss: 0.0283 - acc: 0.9957\n",
      "Epoch 73/100\n",
      "690/690 [==============================] - 0s 351us/step - loss: 0.0281 - acc: 0.9957\n",
      "Epoch 74/100\n",
      "690/690 [==============================] - 0s 270us/step - loss: 0.0270 - acc: 0.9957\n",
      "Epoch 75/100\n",
      "690/690 [==============================] - 0s 245us/step - loss: 0.0243 - acc: 0.9971\n",
      "Epoch 76/100\n",
      "690/690 [==============================] - 0s 225us/step - loss: 0.0263 - acc: 0.9957\n",
      "Epoch 77/100\n",
      "690/690 [==============================] - 0s 233us/step - loss: 0.0275 - acc: 0.9942\n",
      "Epoch 78/100\n",
      "690/690 [==============================] - 0s 233us/step - loss: 0.0244 - acc: 0.9971\n",
      "Epoch 79/100\n",
      "690/690 [==============================] - 0s 225us/step - loss: 0.0243 - acc: 0.9957\n",
      "Epoch 80/100\n",
      "690/690 [==============================] - 0s 224us/step - loss: 0.0252 - acc: 0.9957\n",
      "Epoch 81/100\n",
      "690/690 [==============================] - 0s 231us/step - loss: 0.0234 - acc: 0.9971\n",
      "Epoch 82/100\n",
      "690/690 [==============================] - 0s 223us/step - loss: 0.0242 - acc: 0.9957\n",
      "Epoch 83/100\n",
      "690/690 [==============================] - 0s 234us/step - loss: 0.0253 - acc: 0.9942\n",
      "Epoch 84/100\n",
      "690/690 [==============================] - 0s 221us/step - loss: 0.0220 - acc: 0.9957\n",
      "Epoch 85/100\n",
      "690/690 [==============================] - 0s 215us/step - loss: 0.0239 - acc: 0.9942\n",
      "Epoch 86/100\n",
      "690/690 [==============================] - 0s 222us/step - loss: 0.0251 - acc: 0.9942\n",
      "Epoch 87/100\n",
      "690/690 [==============================] - 0s 267us/step - loss: 0.0219 - acc: 0.9971\n",
      "Epoch 88/100\n",
      "690/690 [==============================] - 0s 321us/step - loss: 0.0238 - acc: 0.9928\n",
      "Epoch 89/100\n",
      "690/690 [==============================] - 0s 221us/step - loss: 0.0209 - acc: 0.9957\n",
      "Epoch 90/100\n",
      "690/690 [==============================] - 0s 225us/step - loss: 0.0192 - acc: 0.9971\n",
      "Epoch 91/100\n",
      "690/690 [==============================] - 0s 223us/step - loss: 0.0218 - acc: 0.9942\n",
      "Epoch 92/100\n",
      "690/690 [==============================] - 0s 221us/step - loss: 0.0207 - acc: 0.9957\n",
      "Epoch 93/100\n",
      "690/690 [==============================] - 0s 240us/step - loss: 0.0204 - acc: 0.9971\n",
      "Epoch 94/100\n",
      "690/690 [==============================] - 0s 221us/step - loss: 0.0218 - acc: 0.9942\n",
      "Epoch 95/100\n",
      "690/690 [==============================] - 0s 219us/step - loss: 0.0199 - acc: 0.9942\n",
      "Epoch 96/100\n",
      "690/690 [==============================] - 0s 228us/step - loss: 0.0221 - acc: 0.9928\n",
      "Epoch 97/100\n",
      "690/690 [==============================] - 0s 221us/step - loss: 0.0211 - acc: 0.9928\n",
      "Epoch 98/100\n",
      "690/690 [==============================] - 0s 223us/step - loss: 0.0199 - acc: 0.9957\n",
      "Epoch 99/100\n",
      "690/690 [==============================] - 0s 242us/step - loss: 0.0231 - acc: 0.9942\n",
      "Epoch 100/100\n",
      "690/690 [==============================] - 0s 224us/step - loss: 0.0183 - acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2e7ef390>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X2, y2, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>Class</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Fraud_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15776156</td>\n",
       "      <td>1</td>\n",
       "      <td>22.08</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.891988e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15739548</td>\n",
       "      <td>0</td>\n",
       "      <td>22.67</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.248447e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15662854</td>\n",
       "      <td>0</td>\n",
       "      <td>29.58</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.574251e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15687688</td>\n",
       "      <td>0</td>\n",
       "      <td>21.67</td>\n",
       "      <td>11.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.541015e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15715750</td>\n",
       "      <td>1</td>\n",
       "      <td>20.17</td>\n",
       "      <td>8.17</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.960</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.124840e-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  A1     A2     A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  \\\n",
       "0    15776156   1  22.08  11.46   2   4   4  1.585   0   0    0    1    2   \n",
       "1    15739548   0  22.67   7.00   2   8   4  0.165   0   0    0    0    2   \n",
       "2    15662854   0  29.58   1.75   1   4   4  1.250   0   0    0    1    2   \n",
       "3    15687688   0  21.67  11.50   1   5   3  0.000   1   1   11    1    2   \n",
       "4    15715750   1  20.17   8.17   2   6   4  1.960   1   1   14    0    2   \n",
       "\n",
       "   A13   A14  Class  Fraud   Fraud_proba  \n",
       "0  100  1213      0      0  1.891988e-20  \n",
       "1  160     1      0      0  1.248447e-07  \n",
       "2  280     1      0      0  7.574251e-06  \n",
       "3    0     1      1      1  8.541015e-01  \n",
       "4   60   159      1      0  4.124840e-21  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_probability = classifier.predict(X2)\n",
    "df['Fraud_proba'] = fraud_probability\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Fraud_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15776156</td>\n",
       "      <td>1.891988e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15739548</td>\n",
       "      <td>1.248447e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15662854</td>\n",
       "      <td>7.574251e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15687688</td>\n",
       "      <td>8.541015e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15715750</td>\n",
       "      <td>4.124840e-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID   Fraud_proba\n",
       "0    15776156  1.891988e-20\n",
       "1    15739548  1.248447e-07\n",
       "2    15662854  7.574251e-06\n",
       "3    15687688  8.541015e-01\n",
       "4    15715750  4.124840e-21"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['CustomerID', 'Fraud_proba']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here are the customer which have the highest probability of fraud :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Fraud_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>15720725</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>15631267</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>15636521</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>15598614</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>15621244</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>15699238</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>15750104</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>15608804</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>15793825</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15668679</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>15716082</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>15698522</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15738487</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>15705379</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>15694666</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15731586</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>15781875</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>15682686</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>15611189</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>15773421</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>15646535</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>15664793</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>15749964</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>15594305</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>15632789</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>15759387</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>15763579</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>15672912</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>15670029</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>15717700</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>15567834</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>15815095</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>15662189</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>15782159</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>15591035</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>15568469</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>15707602</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15687688</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>15696361</td>\n",
       "      <td>0.854101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>15586479</td>\n",
       "      <td>0.853877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>15694677</td>\n",
       "      <td>0.853543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>15761554</td>\n",
       "      <td>0.852728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>15712483</td>\n",
       "      <td>0.844555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>15742009</td>\n",
       "      <td>0.775859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>15752344</td>\n",
       "      <td>0.609953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15648069</td>\n",
       "      <td>0.469035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>15721504</td>\n",
       "      <td>0.464807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15801473</td>\n",
       "      <td>0.419379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>15593959</td>\n",
       "      <td>0.320684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>15608916</td>\n",
       "      <td>0.318081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerID  Fraud_proba\n",
       "345    15720725     0.854101\n",
       "513    15631267     0.854101\n",
       "174    15636521     0.854101\n",
       "457    15598614     0.854101\n",
       "171    15621244     0.854101\n",
       "167    15699238     0.854101\n",
       "483    15750104     0.854101\n",
       "497    15608804     0.854101\n",
       "291    15793825     0.854101\n",
       "39     15668679     0.854101\n",
       "141    15716082     0.854101\n",
       "646    15698522     0.854101\n",
       "45     15738487     0.854101\n",
       "432    15705379     0.854101\n",
       "133    15694666     0.854101\n",
       "48     15731586     0.854101\n",
       "130    15781875     0.854101\n",
       "124    15682686     0.854101\n",
       "522    15611189     0.854101\n",
       "116    15773421     0.854101\n",
       "529    15646535     0.854101\n",
       "98     15664793     0.854101\n",
       "617    15749964     0.854101\n",
       "61     15594305     0.854101\n",
       "181    15632789     0.854101\n",
       "565    15759387     0.854101\n",
       "246    15763579     0.854101\n",
       "384    15672912     0.854101\n",
       "245    15670029     0.854101\n",
       "373    15717700     0.854101\n",
       "346    15567834     0.854101\n",
       "342    15815095     0.854101\n",
       "265    15662189     0.854101\n",
       "308    15782159     0.854101\n",
       "361    15591035     0.854101\n",
       "304    15568469     0.854101\n",
       "229    15707602     0.854101\n",
       "3      15687688     0.854101\n",
       "296    15696361     0.854101\n",
       "362    15586479     0.853877\n",
       "405    15694677     0.853543\n",
       "220    15761554     0.852728\n",
       "604    15712483     0.844555\n",
       "407    15742009     0.775859\n",
       "411    15752344     0.609953\n",
       "46     15648069     0.469035\n",
       "556    15721504     0.464807\n",
       "131    15801473     0.419379\n",
       "201    15593959     0.320684\n",
       "658    15608916     0.318081"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df.sort_values('Fraud_proba', axis=0, ascending= False)\n",
    "result.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Homework Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the code of the solution is doing exactly the same thing as i've done above ðŸŽ‰ðŸŽ‰ðŸŽ‰ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the matrix of features\n",
    "customers = dataset.iloc[:, 1:].values\n",
    "# Creating the dependent variable\n",
    "is_fraud = np.zeros(len(dataset))\n",
    "for i in range(len(dataset)):\n",
    "    if dataset.iloc[i,0] in frauds:\n",
    "        is_fraud[i] = 1\n",
    "        \n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "customers = sc.fit_transform(customers)\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(customers, is_fraud, batch_size = 1, epochs = 2)\n",
    "\n",
    "# Predicting the probabilities of frauds\n",
    "y_pred = classifier.predict(customers)\n",
    "y_pred = np.concatenate((dataset.iloc[:, 0:1].values, y_pred), axis = 1)\n",
    "y_pred = y_pred[y_pred[:, 1].argsort()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
